{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5de52fe5-7e74-43bc-8b5e-a29f6c1dbaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6f904-4bed-4b81-80a6-9aed9451034f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Submission Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d236e9a-672f-4122-af6c-d634c0d2de11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_dict_t1(stereo):\n",
    "    return {\"Stereotype\": stereo, \"NoStreotype\": 1 - stereo}\n",
    "\n",
    "\n",
    "def soft_dict_t2(row, stereo=\"stereotype\", imp=\"implicit\"):\n",
    "    implicit = row[stereo] * row[imp]\n",
    "    explicit = row[stereo] * (1 - row[imp])\n",
    "    return {\"Implicit\": implicit, \"Explicit\": explicit, \"NoStreotype\": 1 - row[stereo]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa205541-f00c-4970-9075-eb0e7a3ddfe5",
   "metadata": {},
   "source": [
    "We will use the following to convert csv files to the json format used for the evaluation\n",
    "\n",
    "We first transform the test set (validation till test solutions are not released).\n",
    "\n",
    "For the evaluation soft labels, we use the mean of the annotator aggregations, with possible values (0, 1/3, 2/3, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a296d7e5-2894-49a4-a92b-638b9edeeae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_to_json(test, name=\"test\"):\n",
    "    test[\"test_case\"] = \"DETESTS-Dis\"\n",
    "    # T1 HARD\n",
    "    df = test.copy()\n",
    "    df[\"value\"] = np.where(df[\"stereotype\"] == 1, \"Stereotype\", \"NoStereotype\")\n",
    "    df[[\"test_case\", \"id\", \"value\"]].to_json(f\"data/{name}_t1_hard.json\", orient=\"records\", indent=4)\n",
    "\n",
    "    # T2 HARD\n",
    "    df = test.copy()\n",
    "    df[\"value\"] = np.select(\n",
    "        [df[\"implicit\"] == 1, df[\"stereotype\"] == 1], [\"Implicit\", \"Explicit\"], default=\"NoStereotype\"\n",
    "    )\n",
    "    df[[\"test_case\", \"id\", \"value\"]].to_json(f\"data/{name}_t2_hard.json\", orient=\"records\", indent=4)\n",
    "\n",
    "    # T1 SOFT\n",
    "    df = test.copy()\n",
    "    df[\"stereotype_soft\"] = df[[\"stereotype_a1\", \"stereotype_a2\", \"stereotype_a3\"]].mean(axis=1)\n",
    "    df[\"value\"] = df[\"stereotype_soft\"].apply(soft_dict_t1)\n",
    "    df[[\"test_case\", \"id\", \"value\"]].to_json(f\"data/{name}_t1_soft.json\", orient=\"records\", indent=4)\n",
    "\n",
    "    # T2 SOFT\n",
    "    df = test.copy()\n",
    "    df[\"value\"] = df.apply(soft_dict_t2, args=(\"stereotype_soft\", \"implicit_soft\"), axis=1)\n",
    "    df[[\"test_case\", \"id\", \"value\"]].to_json(f\"data/{name}_t2_soft.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9c4fa-53c5-4e4a-bd1c-1620124b5c46",
   "metadata": {},
   "source": [
    "We create a validation partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8d2097da-f07e-422c-9d54-0f159be9d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "df = train\n",
    "train = df.sample(frac=0.8, random_state=42)\n",
    "validation = df.drop(train.index)\n",
    "\n",
    "train.to_csv(\"data/train_val.csv\", index=False)\n",
    "validation.to_csv(\"data/validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d1362b76-41e7-481d-b8ba-b94cf2e0dfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(\"data/validation.csv\")\n",
    "val[\"stereotype_soft\"] = val[[\"stereotype_a1\", \"stereotype_a2\", \"stereotype_a3\"]].mean(axis=1)\n",
    "val[\"implicit_soft\"] = val[[\"implicit_a1\", \"implicit_a2\", \"implicit_a3\"]].mean(axis=1)\n",
    "\n",
    "test_to_json(val, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3aa7828a-2d90-47c5-93d1-a1580073fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## When the test solutions are available\n",
    "# test = pd.read_csv(\"data/test_solutions.csv\")\n",
    "# test[\"stereotype_soft\"] = test[[\"stereotype_a1\", \"stereotype_a2\", \"stereotype_a3\"]].mean(axis=1)\n",
    "# test[\"implicit_soft\"] = test[[\"implicit_a1\", \"implicit_a2\", \"implicit_a3\"]].mean(axis=1)\n",
    "\n",
    "# test_to_json(test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b596038-4e5a-4aec-8821-f2dcc5a4cf8c",
   "metadata": {},
   "source": [
    "The baselines may be converted to json as follows.\n",
    "\n",
    "You can use the same functions for your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1c13e2d9-70bf-48f6-9d70-306effd1d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_t1_hard(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"test_case\"] = \"DETESTS-Dis\"\n",
    "    df[\"value\"] = np.where(df[\"stereotype\"] == 1, \"Stereotype\", \"NoStereotype\")\n",
    "    df[[\"test_case\", \"id\", \"value\"]].to_json(file[:-4] + \".json\", orient=\"records\", indent=4)\n",
    "\n",
    "\n",
    "def json_t2_hard(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"test_case\"] = \"DETESTS-Dis\"\n",
    "    df[\"value\"] = np.select(\n",
    "        [df[\"implicit\"] == 1, df[\"stereotype\"] == 1], [\"Implicit\", \"Explicit\"], default=\"NoStereotype\"\n",
    "    )\n",
    "    df[[\"test_case\", \"id\", \"value\"]].to_json(file[:-4] + \".json\", orient=\"records\", indent=4)\n",
    "\n",
    "\n",
    "def json_t1_soft(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"test_case\"] = \"DETESTS-Dis\"\n",
    "    df[\"value\"] = df[\"stereotype\"].apply(soft_dict_t1)\n",
    "    df[[\"test_case\", \"id\", \"value\"]].to_json(file[:-4] + \".json\", orient=\"records\", indent=4)\n",
    "\n",
    "\n",
    "def json_t2_soft(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df[\"test_case\"] = \"DETESTS-Dis\"\n",
    "    df[\"value\"] = df.apply(soft_dict_t2, axis=1)\n",
    "    df[[\"test_case\", \"id\", \"value\"]].to_json(file[:-4] + \".json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "379b5c74-af14-4adc-92e4-55d2ed51fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(\"baselines/validation/*_t1_hard.csv\"):\n",
    "    json_t1_hard(file)\n",
    "\n",
    "for file in glob.glob(\"baselines/validation/*_t2_hard.csv\"):\n",
    "    json_t2_hard(file)\n",
    "\n",
    "for file in glob.glob(\"baselines/validation/*_t1_soft.csv\"):\n",
    "    json_t1_soft(file)\n",
    "\n",
    "for file in glob.glob(\"baselines/validation/*_t2_soft.csv\"):\n",
    "    json_t2_soft(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd0fa68-ff95-432c-8dda-cd0005d9a1a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "770961ea-8ebe-48a6-9385-33f0848e4b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b6ac8c7d-b580-4818-a2f7-06150282c290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-16 18:49:14,411 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['FMeasure', 'Precision', 'Recall']\n",
      "2024-04-16 18:49:14,478 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "2024-04-16 18:49:14,717 - pyevall.metrics.metrics - INFO -             evaluate() - Executing precision evaluation method\n",
      "2024-04-16 18:49:14,718 - pyevall.metrics.metrics - INFO -             evaluate() - Executing recall evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"DETESTS-Dis\",\n",
      "          \"classes\": {\n",
      "            \"NoStereotype\": 0.7403087478559177,\n",
      "            \"Stereotype\": 0.27698185291308497\n",
      "          },\n",
      "          \"average\": 0.5086453003845013\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.5086453003845013\n",
      "      }\n",
      "    },\n",
      "    \"Precision\": {\n",
      "      \"name\": \"Precision\",\n",
      "      \"acronym\": \"Pr\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"DETESTS-Dis\",\n",
      "          \"classes\": {\n",
      "            \"NoStereotype\": 0.7345132743362832,\n",
      "            \"Stereotype\": 0.283203125\n",
      "          },\n",
      "          \"average\": 0.5088581996681416\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.5088581996681416\n",
      "      }\n",
      "    },\n",
      "    \"Recall\": {\n",
      "      \"name\": \"Recall\",\n",
      "      \"acronym\": \"Re\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"DETESTS-Dis\",\n",
      "          \"classes\": {\n",
      "            \"NoStereotype\": 0.7461964038727524,\n",
      "            \"Stereotype\": 0.27102803738317754\n",
      "          },\n",
      "          \"average\": 0.508612220627965\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.508612220627965\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"tfidf_svc_t1_hard.json\": {\n",
      "      \"name\": \"tfidf_svc_t1_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"validation_t1_hard.json\": {\n",
      "      \"name\": \"validation_t1_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pred = \"baselines/validation/tfidf_svc_t1_hard.json\"\n",
    "gold = \"data/validation_t1_hard.json\"\n",
    "evaluate(pred, gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e1307012-6494-4949-90d1-bb3fd58db4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-16 18:49:14,910 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICMSoft', 'ICMSoftNorm']\n",
      "2024-04-16 18:49:15,091 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n",
      "2024-04-16 18:49:15,735 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM-Soft Normalized evaluation method\n",
      "2024-04-16 18:49:15,735 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n",
      "2024-04-16 18:49:16,485 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Soft evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICMSoft\": {\n",
      "      \"name\": \"Information Contrast Model Soft\",\n",
      "      \"acronym\": \"ICM-Soft\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"DETESTS-Dis\",\n",
      "          \"average\": -1.1243255840284248\n",
      "        }],\n",
      "        \"average_per_test_case\": -1.1243255840284248\n",
      "      }\n",
      "    },\n",
      "    \"ICMSoftNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model Soft\",\n",
      "      \"acronym\": \"ICM-Soft-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"DETESTS-Dis\",\n",
      "          \"average\": 0.3791346881412047\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.3791346881412047\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"beto_t2_soft.json\": {\n",
      "      \"name\": \"beto_t2_soft.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"test_t2_soft.json\": {\n",
      "      \"name\": \"test_t2_soft.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pred = \"baselines/beto_t2_soft.json\"\n",
    "gold = \"data/test_t2_soft.json\"\n",
    "evaluate(pred, gold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
